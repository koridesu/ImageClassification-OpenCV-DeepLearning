{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import operator\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\"\"\"\n",
    "if not os.path.exists(\"imgdata\"):\n",
    "    os.makedirs(\"imgdata\")\n",
    "    if not os.path.exists(\"imgdata/train\"):\n",
    "    os.makedirs(\"imgdata/train\")\n",
    "    if not os.path.exists(\"imgdata/test\"):\n",
    "    os.makedirs(\"imgdata/test\")\n",
    "    if not os.path.exists(\"imgdata/train/backward\"):\n",
    "    os.makedirs(\"imgdata/train/backward\")\n",
    "    if not os.path.exists(\"imgdata/train/forward\"):\n",
    "    os.makedirs(\"imgdata/train/forward\")\n",
    "    if not os.path.exists(\"imgdata/train/left\"):\n",
    "    os.makedirs(\"imgdata/train/left\")\n",
    "    if not os.path.exists(\"imgdata/train/right\"):\n",
    "    os.makedirs(\"imgdata/train/right\")\n",
    "    if not os.path.exists(\"imgdata/train/backward\"):\n",
    "    os.makedirs(\"imgdata/test/backward\")\n",
    "    if not os.path.exists(\"imgdata/test/forward\"):\n",
    "    os.makedirs(\"imgdata/test/forward\")\n",
    "    if not os.path.exists(\"imgdata/test/left\"):\n",
    "    os.makedirs(\"imgdata/test/left\")\n",
    "    if not os.path.exists(\"imgdata/test/right\"):\n",
    "    os.makedirs(\"imgdata/test/right\")\n",
    "\"\"\"\n",
    "\n",
    "if not os.path.exists(\"imgdata\"):\n",
    "    os.makedirs(\"imgdata\")  \n",
    "    os.makedirs(\"imgdata/train\")\n",
    "    os.makedirs(\"imgdata/test\")\n",
    "    os.makedirs(\"imgdata/train/backward\")\n",
    "    os.makedirs(\"imgdata/train/forward\")\n",
    "    os.makedirs(\"imgdata/train/left\")\n",
    "    os.makedirs(\"imgdata/train/right\")\n",
    "    os.makedirs(\"imgdata/test/backward\")\n",
    "    os.makedirs(\"imgdata/test/forward\")\n",
    "    os.makedirs(\"imgdata/test/left\")\n",
    "    os.makedirs(\"imgdata/test/right\")\n",
    "    \n",
    "    \n",
    "    \n",
    "mode = 'train'\n",
    "   \n",
    "       \n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    directory = 'imgdata/'+mode+'/' \n",
    "    # Getting count of existing images\n",
    "    count = {'backward': len(os.listdir(directory+\"/backward\")),\n",
    "             'forward': len(os.listdir(directory+\"/forward\")),\n",
    "             'left': len(os.listdir(directory+\"/left\")),\n",
    "             'right': len(os.listdir(directory+\"/right\"))}\n",
    " \n",
    "    \n",
    "    # Printing the count in each set to the screen\n",
    "    cv2.putText(frame, \"press q for change mode:\"+mode, (10, 100), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"BACKWARD :\"+str(count['backward']), (10, 120), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"FORWARD :\"+str(count['forward']), (10, 140), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"LEFT :\"+str(count['left']), (10, 160), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"RIGHT :\"+str(count['right']), (10, 180), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "  \n",
    "\n",
    "    \n",
    "\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 60\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])-10\n",
    "   \n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "   \n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    roi = cv2.resize(roi, (64, 64)) \n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    #_, mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    #kernel = np.ones((1, 1), np.uint8)\n",
    "    #img = cv2.dilate(mask, kernel, iterations=1)\n",
    "    #img = cv2.erode(mask, kernel, iterations=1)\n",
    "    # do the processing after capturing the image!\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, roi = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == 27: # esc key\n",
    "        break\n",
    "    if interrupt & 0xFF == ord('s'):\n",
    "        cv2.imwrite(directory+'backward/'+str(count['backward'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('w'):\n",
    "        cv2.imwrite(directory+'forward/'+str(count['forward'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('a'):\n",
    "        cv2.imwrite(directory+'left/'+str(count['left'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('d'):\n",
    "        cv2.imwrite(directory+'right/'+str(count['right'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('q'):\n",
    "        if mode == \"train\":\n",
    "            mode=\"test\"\n",
    "        else:\n",
    "            mode=\"train\"\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 401 images belonging to 4 classes.\n",
      "Found 80 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='sigmoid'))\n",
    "model.add(Dense(units=4, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, #normalization here\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #normalization here\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('imgdata/train',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=5,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('imgdata/test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=5,\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical') \n",
    "test_set.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "json_file = open(\"model-bw.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model-bw.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\TestANN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "400/400 [==============================] - 8s 20ms/step - loss: 0.3434 - acc: 0.8665 - val_loss: 0.8936 - val_acc: 0.6200\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 0.0932 - acc: 0.9665 - val_loss: 0.7289 - val_acc: 0.82004 - acc\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 6s 16ms/step - loss: 0.0451 - acc: 0.9840 - val_loss: 0.8732 - val_acc: 0.8000\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 7s 16ms/step - loss: 0.0374 - acc: 0.9900 - val_loss: 1.1038 - val_acc: 0.7700\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 6s 16ms/step - loss: 0.0350 - acc: 0.9885 - val_loss: 0.6258 - val_acc: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15f7571a688>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=400,\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_json = model.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model-bw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "categories = {0: 'BACKWARD', 1: 'FORWARD', 2: 'LEFT', 3: 'RIGHT'}\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 10\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])\n",
    "   \n",
    "\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    \n",
    "\n",
    "    roi = cv2.resize(roi, (64, 64)) \n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, test_image = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"test\", test_image)\n",
    "    \n",
    "    \n",
    "    result = model.predict(test_image.reshape(1, 64, 64, 1))\n",
    "    \n",
    "    prediction = {'BACKWARD': result[0][0], \n",
    "                  'FORWARD': result[0][1], \n",
    "                  'LEFT': result[0][2],\n",
    "                  'RIGHT': result[0][3]}\n",
    "\n",
    "    prediction = sorted(prediction.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    # Displaying the predictions\n",
    "    cv2.putText(frame, prediction[0][0], (10, 120), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == 27: # esc key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
